{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the tracking data\n",
    "df = pd.read_csv('tracking_week_1.csv')\n",
    "\n",
    "# Look at the structure and some basic stats\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\\n",
    "Columns:\", df.columns.tolist())\n",
    "print(\"\\\n",
    "Sample of pre-snap data:\")\n",
    "print(df[df['frameType'] == 'BEFORE_SNAP'].head())\n",
    "\n",
    "# Get unique events\n",
    "print(\"\\\n",
    "Unique events in the data:\")\n",
    "print(df['event'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv('tracking_week_1.csv')\n",
    "\n",
    "# Group by play and get pre-snap sequences\n",
    "play_groups = df.groupby(['gameId', 'playId'])\n",
    "\n",
    "# Function to analyze pre-snap motion\n",
    "def analyze_presnap(group):\n",
    "    presnap = group[group['frameType'] == 'BEFORE_SNAP']\n",
    "    \n",
    "    # Check for motion\n",
    "    has_motion = 'man_in_motion' in group['event'].values\n",
    "    has_shift = 'shift' in group['event'].values\n",
    "    \n",
    "    # Get play outcome\n",
    "    play_events = group['event'].dropna().unique()\n",
    "    touchdown = 'touchdown' in play_events\n",
    "    \n",
    "    # Calculate motion metrics\n",
    "    max_speed = presnap['s'].max()\n",
    "    total_displacement = presnap.groupby('nflId')['dis'].sum().mean()\n",
    "    \n",
    "    return pd.Series({\n",
    "        'has_motion': has_motion,\n",
    "        'has_shift': has_shift,\n",
    "        'touchdown': touchdown,\n",
    "        'max_presnap_speed': max_speed,\n",
    "        'avg_displacement': total_displacement\n",
    "    })\n",
    "\n",
    "# Apply analysis to each play\n",
    "play_metrics = play_groups.apply(analyze_presnap)\n",
    "\n",
    "# Calculate success rates\n",
    "motion_success = play_metrics[play_metrics['has_motion']]['touchdown'].mean()\n",
    "no_motion_success = play_metrics[~play_metrics['has_motion']]['touchdown'].mean()\n",
    "\n",
    "print(\"Plays with motion touchdown rate: {:.1%}\".format(motion_success))\n",
    "print(\"Plays without motion touchdown rate: {:.1%}\".format(no_motion_success))\n",
    "\n",
    "# Visualize the relationship between motion and outcomes\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=play_metrics, x='has_motion', y='max_presnap_speed')\n",
    "plt.title('Pre-snap Speed Distribution by Motion Usage')\n",
    "plt.show()\n",
    "\n",
    "# Basic stats about motion usage\n",
    "print(\"\\\n",
    "Motion usage statistics:\")\n",
    "print(\"Total plays:\", len(play_metrics))\n",
    "print(\"Plays with motion:\", play_metrics['has_motion'].sum())\n",
    "print(\"Plays with shifts:\", play_metrics['has_shift'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to extract pre-snap features\n",
    "def extract_presnap_features(group):\n",
    "    presnap = group[group['frameType'] == 'BEFORE_SNAP']\n",
    "    \n",
    "    # Motion detection\n",
    "    has_motion = 'man_in_motion' in group['event'].values\n",
    "    has_shift = 'shift' in group['event'].values\n",
    "    \n",
    "    # Speed and movement features\n",
    "    max_speed = presnap['s'].max()\n",
    "    avg_speed = presnap['s'].mean()\n",
    "    total_displacement = presnap.groupby('nflId')['dis'].sum().mean()\n",
    "    \n",
    "    # Formation spread\n",
    "    last_frame = presnap[presnap['frameId'] == presnap['frameId'].max()]\n",
    "    if len(last_frame) > 1:\n",
    "        x_spread = last_frame['x'].max() - last_frame['x'].min()\n",
    "        y_spread = last_frame['y'].max() - last_frame['y'].min()\n",
    "    else:\n",
    "        x_spread = 0\n",
    "        y_spread = 0\n",
    "    \n",
    "    # Motion timing\n",
    "    snap_frame = group[group['event'] == 'ball_snap']['frameId'].min() if 'ball_snap' in group['event'].values else group['frameId'].max()\n",
    "    if has_motion:\n",
    "        motion_frames = group[group['event'] == 'man_in_motion']['frameId'].min()\n",
    "        frames_before_snap = snap_frame - motion_frames\n",
    "    else:\n",
    "        frames_before_snap = 0\n",
    "        \n",
    "    return pd.Series({\n",
    "        'has_motion': has_motion,\n",
    "        'has_shift': has_shift,\n",
    "        'max_presnap_speed': max_speed,\n",
    "        'avg_presnap_speed': avg_speed,\n",
    "        'avg_displacement': total_displacement,\n",
    "        'formation_x_spread': x_spread,\n",
    "        'formation_y_spread': y_spread,\n",
    "        'motion_timing': frames_before_snap\n",
    "    })\n",
    "\n",
    "# Group by play and extract features\n",
    "play_groups = merged_df.groupby(['gameId', 'playId'])\n",
    "play_features = play_groups.apply(extract_presnap_features)\n",
    "\n",
    "# Add play outcomes\n",
    "play_outcomes = merged_df.groupby(['gameId', 'playId']).agg({\n",
    "    'expectedPoints': 'first',\n",
    "    'yardsGained': 'first',\n",
    "    'offenseFormation': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Combine features and outcomes\n",
    "analysis_df = play_features.reset_index().merge(play_outcomes, on=['gameId', 'playId'])\n",
    "\n",
    "# Calculate average EPA by motion usage\n",
    "motion_analysis = analysis_df.groupby('has_motion').agg({\n",
    "    'expectedPoints': ['mean', 'std', 'count'],\n",
    "    'yardsGained': ['mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "print(\"Motion Analysis:\")\n",
    "print(motion_analysis)\n",
    "\n",
    "# Visualize EPA distribution by motion\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=analysis_df, x='has_motion', y='expectedPoints')\n",
    "plt.title('Expected Points by Motion Usage')\n",
    "plt.show()\n",
    "\n",
    "# Analyze motion timing impact\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=analysis_df[analysis_df['has_motion']], \n",
    "                x='motion_timing', y='expectedPoints')\n",
    "plt.title('Motion Timing vs Expected Points')\n",
    "plt.show()\n",
    "\n",
    "# Formation analysis\n",
    "formation_motion = pd.crosstab(analysis_df['offenseFormation'], \n",
    "                             analysis_df['has_motion'], \n",
    "                             values=analysis_df['expectedPoints'], \n",
    "                             aggfunc='mean').round(2)\n",
    "print(\"\\\n",
    "Expected Points by Formation and Motion:\")\n",
    "print(formation_motion)\n",
    "\n",
    "# Calculate correlations between features and outcomes\n",
    "feature_cols = ['has_motion', 'has_shift', 'max_presnap_speed', \n",
    "                'avg_presnap_speed', 'avg_displacement', \n",
    "                'formation_x_spread', 'formation_y_spread']\n",
    "correlation_matrix = analysis_df[feature_cols + ['expectedPoints', 'yardsGained']].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdBu', center=0)\n",
    "plt.title('Feature Correlations with Outcomes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Filter data for I_FORM and EMPTY formations\n",
    "formation_focus = analysis_df[analysis_df['offenseFormation'].isin(['I_FORM', 'EMPTY'])]\n",
    "\n",
    "# Group by formation and motion usage\n",
    "formation_analysis = formation_focus.groupby(['offenseFormation', 'has_motion']).agg({\n",
    "    'expectedPoints': ['mean', 'std', 'count'],\n",
    "    'yardsGained': ['mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "print(\"Detailed Analysis for I_FORM and EMPTY formations:\")\n",
    "print(formation_analysis)\n",
    "\n",
    "# Visualize expected points for these formations\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=formation_focus, x='offenseFormation', y='expectedPoints', hue='has_motion')\n",
    "plt.title('Expected Points by Formation and Motion Usage')\n",
    "plt.show()\n",
    "\n",
    "# Analyze correlation of features for these formations\n",
    "formation_corr = formation_focus[['has_motion', 'max_presnap_speed', 'avg_presnap_speed', \n",
    "                                   'avg_displacement', 'formation_x_spread', 'formation_y_spread', \n",
    "                                   'expectedPoints', 'yardsGained']].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(formation_corr, annot=True, cmap='RdBu', center=0)\n",
    "plt.title('Feature Correlations for I_FORM and EMPTY Formations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Additional analysis of play success rates\n",
    "def calculate_success_rate(group):\n",
    "    # Define success criteria: 40% of yards needed on first down, 60% on second down, 100% on third/fourth down\n",
    "    success = ((group['down'] == 1) & (group['yardsGained'] >= 0.4 * group['yardsToGo'])) | \\\n",
    "             ((group['down'] == 2) & (group['yardsGained'] >= 0.6 * group['yardsToGo'])) | \\\n",
    "             ((group['down'].isin([3, 4])) & (group['yardsGained'] >= group['yardsToGo']))\n",
    "    return success.mean()\n",
    "\n",
    "# Merge with plays data to get down and distance information\n",
    "formation_focus = formation_focus.merge(\n",
    "    plays_df[['gameId', 'playId', 'down', 'yardsToGo']], \n",
    "    on=['gameId', 'playId']\n",
    ")\n",
    "\n",
    "# Calculate success rates by formation and motion\n",
    "success_rates = formation_focus.groupby(['offenseFormation', 'has_motion']).apply(calculate_success_rate)\n",
    "print(\"\\\n",
    "Success Rates by Formation and Motion:\")\n",
    "print(success_rates)\n",
    "\n",
    "# Analyze by down\n",
    "down_analysis = formation_focus.groupby(['offenseFormation', 'has_motion', 'down']).agg({\n",
    "    'expectedPoints': ['mean', 'count'],\n",
    "    'yardsGained': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\\n",
    "Analysis by Down:\")\n",
    "print(down_analysis)\n",
    "\n",
    "# Visualize EPA by down for each formation\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=formation_focus, x='down', y='expectedPoints', \n",
    "            hue='offenseFormation', palette='Set2')\n",
    "plt.title('Expected Points by Down and Formation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Let's first load and prepare our data properly\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the tracking data\n",
    "df = pd.read_csv('tracking_week_1.csv')\n",
    "\n",
    "# Create basic features for modeling\n",
    "df['has_motion'] = df['event'].notna() & df['event'].str.contains('motion', na=False)\n",
    "df['presnap'] = df['frameType'] == 'BEFORE_SNAP'\n",
    "\n",
    "# Group by play to get play-level features\n",
    "play_features = df[df['presnap']].groupby(['gameId', 'playId']).agg({\n",
    "    'x': ['std', 'mean'],\n",
    "    'y': ['std', 'mean'],\n",
    "    's': ['max', 'mean'],  # speed\n",
    "    'a': ['max', 'mean'],  # acceleration\n",
    "    'has_motion': 'max',\n",
    "    'o': ['std', 'mean']  # orientation\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "play_features.columns = ['gameId', 'playId', \n",
    "                        'x_spread', 'x_mean',\n",
    "                        'y_spread', 'y_mean',\n",
    "                        'max_speed', 'avg_speed',\n",
    "                        'max_accel', 'avg_accel',\n",
    "                        'has_motion',\n",
    "                        'o_spread', 'o_mean']\n",
    "\n",
    "print(\"Features created per play:\")\n",
    "print(play_features.head())\n",
    "\n",
    "# Look at distributions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(data=play_features, x='x_spread', hue='has_motion')\n",
    "plt.title('Formation Spread (X) Distribution')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(data=play_features, x='max_speed', hue='has_motion')\n",
    "plt.title('Max Speed Distribution')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(data=play_features, x='y_spread', hue='has_motion')\n",
    "plt.title('Formation Spread (Y) Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\\n",
    "Summary statistics for key features:\")\n",
    "print(play_features.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error\n",
    "\n",
    "# Prepare data for modeling\n",
    "# Target variable: Play success (binary classification)\n",
    "play_features['successful_play'] = (\n",
    "    (play_features['max_speed'] > 4) & (play_features['x_spread'] > 3)\n",
    ").astype(int)\n",
    "\n",
    "# Features for classification and regression\n",
    "feature_cols = ['x_spread', 'y_spread', 'max_speed', 'avg_speed', 'max_accel', 'avg_accel', 'o_spread']\n",
    "X = play_features[feature_cols]\n",
    "\n",
    "# Classification target\n",
    "y_class = play_features['successful_play']\n",
    "\n",
    "# Regression target\n",
    "y_reg = play_features['x_spread']  # Example regression target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X, y_class, test_size=0.3, random_state=42)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.3, random_state=42)\n",
    "\n",
    "# Classification model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_class, y_train_class)\n",
    "y_pred_class = clf.predict(X_test_class)\n",
    "\n",
    "# Regression model\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = reg.predict(X_test_reg)\n",
    "\n",
    "# Evaluate models\n",
    "classification_accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "classification_auc = roc_auc_score(y_test_class, clf.predict_proba(X_test_class)[:, 1])\n",
    "regression_mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"Classification Model Performance:\")\n",
    "print(\"Accuracy:\", classification_accuracy)\n",
    "print(\"AUC:\", classification_auc)\n",
    "\n",
    "print(\"\\\n",
    "Regression Model Performance:\")\n",
    "print(\"Mean Squared Error:\", regression_mse)\n",
    "\n",
    "# Feature importance\n",
    "importances_class = clf.feature_importances_\n",
    "importances_reg = reg.feature_importances_\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(feature_cols, importances_class)\n",
    "plt.title('Feature Importance (Classification)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(feature_cols, importances_reg)\n",
    "plt.title('Feature Importance (Regression)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the data again and create more sophisticated features\n",
    "df = pd.read_csv('tracking_week_1.csv')\n",
    "\n",
    "# Create time-based features\n",
    "df['time_to_snap'] = df.groupby(['gameId', 'playId'])['frameId'].transform('max') - df['frameId']\n",
    "df['presnap'] = df['frameType'] == 'BEFORE_SNAP'\n",
    "\n",
    "# Calculate more sophisticated pre-snap features\n",
    "play_features = df[df['presnap']].groupby(['gameId', 'playId']).agg({\n",
    "    'x': ['std', 'mean', 'min', 'max'],  # Formation spread and position\n",
    "    'y': ['std', 'mean', 'min', 'max'],\n",
    "    's': ['max', 'mean', 'std'],  # Speed features\n",
    "    'a': ['max', 'mean', 'std'],  # Acceleration features\n",
    "    'dir': ['std', 'mean'],  # Directional movement\n",
    "    'o': ['std', 'mean'],    # Orientation\n",
    "    'time_to_snap': ['min']  # Timing features\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "play_features.columns = ['gameId', 'playId', \n",
    "                        'x_spread', 'x_mean', 'x_min', 'x_max',\n",
    "                        'y_spread', 'y_mean', 'y_min', 'y_max',\n",
    "                        'speed_max', 'speed_mean', 'speed_std',\n",
    "                        'accel_max', 'accel_mean', 'accel_std',\n",
    "                        'dir_std', 'dir_mean',\n",
    "                        'orient_std', 'orient_mean',\n",
    "                        'time_to_snap']\n",
    "\n",
    "# Add formation complexity metrics\n",
    "play_features['formation_area'] = (play_features['x_max'] - play_features['x_min']) * (play_features['y_max'] - play_features['y_min'])\n",
    "play_features['speed_complexity'] = play_features['speed_std'] * play_features['speed_max']\n",
    "play_features['movement_complexity'] = play_features['dir_std'] * play_features['speed_mean']\n",
    "\n",
    "# Create a more sophisticated success metric\n",
    "# Let's say a play is \"deceptive\" if it shows complex pre-snap movement\n",
    "play_features['deceptive_play'] = (\n",
    "    (play_features['speed_complexity'] > play_features['speed_complexity'].median()) &\n",
    "    (play_features['movement_complexity'] > play_features['movement_complexity'].median()) &\n",
    "    (play_features['formation_area'] > play_features['formation_area'].median())\n",
    ").astype(int)\n",
    "\n",
    "# Prepare features for modeling\n",
    "feature_cols = ['x_spread', 'y_spread', 'speed_max', 'speed_mean', 'speed_std',\n",
    "                'accel_max', 'accel_mean', 'accel_std', 'dir_std', 'orient_std',\n",
    "                'formation_area', 'speed_complexity', 'movement_complexity']\n",
    "\n",
    "X = play_features[feature_cols]\n",
    "y = play_features['deceptive_play']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=feature_cols)\n",
    "\n",
    "# Train a gradient boosting model with cross-validation\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "cv_scores = cross_val_score(gb_model, X_scaled, y, cv=5)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Average CV score:\", cv_scores.mean())\n",
    "\n",
    "# Fit the model on full dataset for feature importance\n",
    "gb_model.fit(X_scaled, y)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 6))\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': gb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "plt.barh(y=range(len(importance_df)), width=importance_df['importance'])\n",
    "plt.yticks(range(len(importance_df)), importance_df['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance in Predicting Deceptive Plays')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze relationships between key features\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.scatterplot(data=play_features, x='speed_complexity', y='movement_complexity', \n",
    "                hue='deceptive_play', alpha=0.6)\n",
    "plt.title('Speed vs Movement Complexity')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.scatterplot(data=play_features, x='formation_area', y='speed_max',\n",
    "                hue='deceptive_play', alpha=0.6)\n",
    "plt.title('Formation Area vs Max Speed')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=play_features, x='deceptive_play', y='speed_complexity')\n",
    "plt.title('Speed Complexity by Play Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics for deceptive vs non-deceptive plays\n",
    "print(\"\\\n",
    "Summary Statistics for Deceptive vs Non-Deceptive Plays:\")\n",
    "print(play_features.groupby('deceptive_play')[\n",
    "    ['speed_complexity', 'movement_complexity', 'formation_area']\n",
    "].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data for transformer model\n",
    "class PreSnapDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "# Convert play-level features into sequences\n",
    "sequence_features = ['x_spread', 'y_spread', 'speed_max', 'speed_mean', 'speed_std',\n",
    "                     'accel_max', 'accel_mean', 'accel_std', 'dir_std', 'orient_std']\n",
    "\n",
    "X_sequences = play_features[sequence_features].values\n",
    "y_sequences = play_features['deceptive_play'].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = PreSnapDataset(X_train, y_train)\n",
    "test_dataset = PreSnapDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_layers, hidden_dim, output_dim):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)  # Global average pooling\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Model parameters\n",
    "input_dim = len(sequence_features)\n",
    "hidden_dim = 64\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = TransformerModel(input_dim, num_heads, num_layers, hidden_dim, output_dim)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs.squeeze(), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(\"Epoch\", epoch + 1, \"Loss:\", total_loss / len(train_loader))\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            predictions.extend(torch.sigmoid(outputs).round().numpy())\n",
    "            actuals.extend(y_batch.numpy())\n",
    "    return predictions, actuals\n",
    "\n",
    "predictions, actuals = evaluate_model(model, test_loader)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (np.array(predictions) == np.array(actuals)).mean()\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
